{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "658bb378-dbc1-4e1a-a7b9-db325bd5147e",
   "metadata": {},
   "source": [
    "# BERTopic Analysis for Screenplays\n",
    "\n",
    "## Current Notebook Workflow\n",
    "\n",
    "### 1. Import Data\n",
    "- Load screenplay text.\n",
    "- Load words to remove (stop words, character names, common screenplay words).\n",
    "\n",
    "### 2. Clean the Screenplay\n",
    "- Convert to lowercase.\n",
    "- Remove numbers and special characters.\n",
    "- Filter out words to remove (stop words, character names, etc.).\n",
    "\n",
    "### 3. Format Text for BERT\n",
    "- Convert screenplay text into **chunks** (currently non-overlapping).\n",
    "- **Planned improvement:** Implement **rolling window chunking** (e.g., 300-word chunks with 100-word overlap).\n",
    "\n",
    "### 4. Load Subgenres & Genres\n",
    "- Load predefined **genres and subgenres**.\n",
    "- Concatenate **descriptions** to each genre/subgenre label to improve **zero-shot classification accuracy**.\n",
    "\n",
    "### 5. Run BERTopic\n",
    "- Train BERTopic model on the screenplay chunks.\n",
    "- Generate and save visualizations:\n",
    "  - **Topic Bar Chart**\n",
    "  - **Dendrogram**\n",
    "  - **Inter-Topic Distance Map**\n",
    "\n",
    "### 6. Zero-Shot Classification\n",
    "- Perform **zero-shot classification** on genres and subgenres **for each chunk**.\n",
    "- Assign predicted genres/subgenres to chunks based on topic distributions.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### 1. Improve Chunking\n",
    "- Modify text preprocessing to **include overlapping chunks** (e.g., 300-word chunks with 100-word overlap).\n",
    "- Update chunking logic to ensure **better context retention** across segments.\n",
    "\n",
    "### 2. Train BERTopic on a Larger Corpus\n",
    "- Use **30 selected screenplays** from the `screenplay_text/` folder as a **training set**.\n",
    "- Train BERTopic **on all 30 scripts** to **learn better topic structures**.\n",
    "\n",
    "### 3. Evaluate Model Performance\n",
    "- **Determine a metric for evaluation** (currently undecided).\n",
    "- Possible approach: Measure **accuracy** of BERTopic’s **top predicted genres/subgenres**.\n",
    "- **Challenge:** No ground truth labels available yet → Need to **label some scripts manually**.\n",
    "\n",
    "### 4. Optimize Zero-Shot Classification Strategy\n",
    "- Consider **removing zero-shot classification from BERTopic** and **running it separately**.\n",
    "- Alternative approach:\n",
    "  - Export **BERTopic’s topic word distributions**.\n",
    "  - Use **zero-shot classification in a separate environment** (e.g., **Hugging Face**).\n",
    "  - Classify topics **based on their top words** instead of per-chunk classification.\n",
    "\n",
    "### 5. Optimize Performance & Scaling\n",
    "- Consider **precomputing BERT embeddings** and storing them in a **vector database** (e.g., FAISS, Weaviate) to **speed up training**.\n",
    "- Monitor memory usage as dataset size increases.\n",
    "\n",
    "---\n",
    "\n",
    "### Notes:\n",
    "- **Next Immediate Task:** Implement **rolling window chunking** and test performance.\n",
    "- **Potential Bottleneck:** Increasing dataset size may require **parallelized processing** for efficiency.\n",
    "- **Long-Term Goal:** Create a stable **BERTopic model trained on a corpus of screenplays**, which can be used for more robust **genre/subgenre classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37552361-605f-4362-aa8c-a46b0202996b",
   "metadata": {},
   "source": [
    "### PREP TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efea29c3-cd6f-42af-92cc-5b48c154cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 screenplays loaded for training.\n",
      "\n",
      "2001 A SPACE ODYSSEY\n",
      "Screenplay\n",
      "by\n",
      "Stanley Kubrick and Arthur C Clark\n",
      "\n",
      "Hawk Films Ltd\n",
      "co M-G-M Studios\n",
      "Boreham Wood\n",
      "Herts\n",
      "\n",
      "TITLE PART I\n",
      "AFRICA\n",
      "3000000 YEARS AGO\n",
      "\n",
      "Al\n",
      "VIEWS OF AFRICAN DRYLANDS - DROUGHT\n",
      "\n",
      "The remorseless drought had lasted now for ten million years\n",
      "and would not end for another million\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "import os\n",
    "\n",
    "def get_filenames(directory):\n",
    "    return [f for f in os.listdir(directory) if f.endswith('.txt')]\n",
    "\n",
    "\n",
    "def get_screenplay(movie_title):\n",
    "    screenplay_path = f\"../data/screenplays/text_from_ocr/{movie_title}\"\n",
    "\n",
    "    if not os.path.exists(screenplay_path):\n",
    "        print(f\"Error: Screenplay '{movie_title}.txt' not found in the folder.\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        with open(screenplay_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            screenplay_text = f.read()\n",
    "        return screenplay_text\n",
    "    except Exception as e:\n",
    "        print (f\"Error reading screenplay '{movie_title}.txt': {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"../data/screenplays/train\"\n",
    "train_screenplays = get_filenames(directory_path)\n",
    "print(len(train_screenplays), \"screenplays loaded for training.\\n\")\n",
    "\n",
    "screenplay_text = get_screenplay(train_screenplays[0])\n",
    "print(screenplay_text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e2d9b1-5f82-4173-bd8f-ecfb7b35c561",
   "metadata": {},
   "source": [
    "### LOAD WORDS TO REMOVE FROM SCREENPLAY\n",
    "- Character names\n",
    "- stopwords\n",
    "- 200 most common words in screenplays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6d369e-91b2-4a74-8768-22630b9a5fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words loaded.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['john', 'mcclane', 'hans', 'gruber', 'karl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load character names\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import re\n",
    "\n",
    "def load_character_names(movie_title):\n",
    "    with open(f\"../data/movie_data/{movie_title.replace(\" \", \"_\")}.json\", \"r\", encoding=\"utf-8\") as file2:\n",
    "        character_names = json.load(file2)\n",
    "        \n",
    "    characters = [dicty[\"character\"] for dicty in character_names[\"actors_characters\"]]\n",
    "    characters_cleaned = []\n",
    "    for char in characters:\n",
    "         names = char.split(\" \")\n",
    "         for name in names: \n",
    "             name = re.sub(r\"[^a-z]\", \"\", name.lower())\n",
    "             if name != \"\":\n",
    "                 characters_cleaned.append(name)\n",
    "\n",
    "    return characters_cleaned\n",
    "\n",
    "def load_words(top_n_common=200):\n",
    "    # stop words\n",
    "    with open(\"word_frequencies.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        word_frequencies = json.load(file)\n",
    "\n",
    "    common_words = list(word_frequencies.keys())[:top_n_common]\n",
    "    stop_words = list(set(stopwords.words('english')))\n",
    "\n",
    "    return common_words + stop_words\n",
    "    \n",
    "words_to_remove = load_words(top_n_common=200)\n",
    "characters = load_character_names(movie_title=\"Die Hard\")\n",
    "print(\"Words loaded.\\n\")\n",
    "characters[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c0fd01-8878-4503-acd9-b44515b92a39",
   "metadata": {},
   "source": [
    "### LOAD SUB-GENRES FOR ZERO-SHOT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59f175f9-2654-4605-8300-88e03de99233",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action The action genre features fast-paced, thrilling, and intense sequences of physical feats, combat, and excitement. The characters of these stories are involved in daring and often dangerous situations, requiring them to rely on their physical prowess, skills, and quick thinking to overcome challenges and adversaries.',\n",
       " 'Adventure The adventure genre features exciting journeys, quests, or expeditions undertaken by characters who often face challenges, obstacles, and risks in pursuit of a goal. Adventures can take place in a wide range of settings, from exotic and fantastical locations to historical or even everyday environments.',\n",
       " 'Biography The biography, or \"biopic\", is a genre that portrays the life story of a real person, often a notable individual or historical figure. They aim to provide a depiction of the subject\\'s personal history, achievements, challenges, and impact on society.',\n",
       " 'Comedy The comedy genre refers to a category of entertainment that aims to amuse and entertain audiences by using humor, wit, and comedic situations. Comedies are created with the primary intention of eliciting laughter and providing lighthearted enjoyment. They encompass a wide range of styles, tones, and themes, appealing to various tastes and audiences.',\n",
       " 'Crime The crime genre features criminal activities, investigations, law enforcement, crimes, and the pursuit of justice. Crime stories often revolve around the planning, execution, and consequences of criminal acts, as well as the efforts to solve and prevent such acts. They explore various aspects of criminal behavior, motives, and the moral dilemmas faced by both perpetrators and those seeking to uphold the law.',\n",
       " 'Drama The drama genre is a broad category that features stories portraying human experiences, emotions, conflicts, and relationships in a realistic and emotionally impactful way. Dramas delve into the complexities of human life, often exploring themes of love, loss, morality, societal issues, personal growth, with the aim to evoke an emotional response from the audience by presenting relatable and thought-provoking stories.',\n",
       " 'Family The family genre features stories specifically created to be suitable for a wide range of age groups within a family. Family-oriented content is designed to be enjoyed by both children and adults, often providing entertainment that is wholesome, relatable, and appropriate for all members of a family to watch or experience together.',\n",
       " 'History The history genre features recounting and analyzing past events, societies, cultures, and historical figures. This genre aims to provide insights into the development of civilizations, the causes and consequences of historical events, and the impact of individuals and ideas on the course of history.',\n",
       " \"Holiday The holiday genre features winter holidays, such as Christmas, Thanksgiving, Hanukkah, New Year's Eve, or other cultural and religious celebrations. These stories often capture the spirit, traditions, and emotions associated with these special times, making them ideal for seasonal viewing. The holiday genre can further branch into subgenres like holiday comedy, holiday romance, and holiday family.\",\n",
       " 'Horror The horror genre features stories that aim to elicit fear, suspense, and a sense of dread in its audience. Horror stories often explore themes related to the unknown, the supernatural, and the macabre, and they frequently evoke strong emotional reactions such as anxiety, terror, and unease.',\n",
       " 'Sport The sport genre features the world of sports, capturing the excitement, competition, and personal journeys of athletes, coaches, and teams. The stories cover a wide range of sports and activities, each with its own unique characteristics and themes.',\n",
       " 'Thriller The thriller genre features suspense, tension, and excitement. These stories are known for keeping audiences on the edge of their seats and delivering intense emotional experiences by revolving around high-stakes situations, dangerous conflicts, and the constant anticipation of unexpected events.',\n",
       " 'War The war genre features armed conflicts, both historical and fictional, and the experiences of individuals and groups involved in warfare. This genre explores the physical, emotional, and moral challenges faced by soldiers, civilians, and others affected by war.',\n",
       " 'Western The Western genre features stories set primarily in the 19th-century American Old West and often depict the rugged frontier life, exploring themes of individualism, justice, morality, and the clash between civilization and the untamed wilderness. The genre has its roots in the historical context of westward expansion and the challenges faced by pioneers, settlers, outlaws, and lawmen.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load subgenres\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_genres_and_subgenres(json_path=\"../data/IMDb/parsed_subgenres.json\"):\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(json_path):\n",
    "        return \"Error: JSON file not found.\"\n",
    "\n",
    "    try:\n",
    "        # Load JSON data\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Separate genres and subgenres into dictionaries\n",
    "        genres_dicts = []\n",
    "        subgenres_dicts = []\n",
    "\n",
    "        for entry in data:\n",
    "            title = entry.get(\"title\")\n",
    "            description = entry.get(\"description\")\n",
    "            category = entry.get(\"type\", \"\").lower()  # Normalize category name\n",
    "\n",
    "            if title and description:\n",
    "                temp_dict = {\"title\": title, \"description\": description}\n",
    "                \n",
    "                if \"subgenre\" == category:  # If categorized as a subgenre\n",
    "                    subgenres_dicts.append(temp_dict)\n",
    "                elif \"genre\" == category:  # Default to genre\n",
    "                    genres_dicts.append(temp_dict)\n",
    "\n",
    "        return genres_dicts, subgenres_dicts, data\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Failed to parse JSON file (invalid format).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "\n",
    "\n",
    "genres_dicts, subgenres_dicts, data = load_genres_and_subgenres()\n",
    "\n",
    "verbose = False\n",
    "if verbose:\n",
    "    for d in genres_dicts:\n",
    "        print(d[\"title\"])\n",
    "        print(d[\"description\"])\n",
    "        print()\n",
    "        \n",
    "subgenres_list = [dicty[\"title\"] for dicty in subgenres_dicts]\n",
    "subgenres_descriptions_list = [dicty[\"title\"] + \" \" + dicty[\"description\"] for dicty in subgenres_dicts]\n",
    "\n",
    "genres_list = [dicty[\"title\"] for dicty in genres_dicts]\n",
    "genres_descriptions_list = [dicty[\"title\"] + \" \" + dicty[\"description\"] for dicty in genres_dicts]\n",
    "\n",
    "genres_descriptions_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a74103-54e9-484e-8f47-599fba09d5a6",
   "metadata": {},
   "source": [
    "### CLEAN TEXT\n",
    "- Lowercase, remove non-letter characters\n",
    "- filter out common words and stopwords and character names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87388a6-9e2b-4ce5-ab22-8d602d2ce416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text\n",
    "def clean_and_chunk_text(screenplay_text, movie_title, top_n_common=200, verbose=True, chunk_size=35):\n",
    "    cleaned_words = screenplay_text.lower().replace(\"\\n\", \" \")                \n",
    "    cleaned_words = [re.sub(r\"[^a-zA-Z]\", \"\", word.strip()) for word in cleaned_words.split(\" \") if word.strip() != \"\"]\n",
    "    \n",
    "    # Filter out stop words, character names, and common words\n",
    "    words_to_remove = load_words(top_n_common=200)\n",
    "    characters = load_character_names(movie_title=movie_title)\n",
    "    filtered_words = [word for word in cleaned_words if word not in (words_to_remove or characters)]\n",
    "    \n",
    "    # filter out short words\n",
    "    filtered_words = [word for word in filtered_words if len(word) > 2]\n",
    "\n",
    "    # chunks\n",
    "    chunks = [\" \".join(filtered_words[i:i+chunk_size]) for i in range(0, len(filtered_words), chunk_size)]\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Original words: {len(cleaned_words)}, Filtered words: {len(filtered_words)}\")\n",
    "        print(f\"Total chunks: {len(chunks)}\")\n",
    "\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3febe0ec-87bd-48ab-8b43-08e5cb9bdeb1",
   "metadata": {},
   "source": [
    "### RUN BERTOPIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ea957b-a8e9-4553-a6be-35e447b4c966",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "from umap import UMAP\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "\n",
    "def create_plots(topic_model, movie_title, top_n_topics=10):\n",
    "    # barcharts\n",
    "    fig = topic_model.visualize_barchart(top_n_topics=top_n_topics)\n",
    "    fig.update_layout(title_text=f\"Top 10 BERTopic distributions in {movie_title}\", title_x=0.5)  # Centered title\n",
    "    fig.write_html(f\"plots/{movie_title}_bertopic_barchart.html\")\n",
    "\n",
    "    # intertopic distances\n",
    "    fig2 = topic_model.visualize_topics()\n",
    "    fig2.update_layout(title_text=f\"Intertopic Distance Map for {movie_title}\", title_x=0.5)  # Centered title\n",
    "    fig2.write_html(f\"plots/{movie_title}_intertopic_distance.html\")\n",
    "\n",
    "    # dendogram\n",
    "    fig3 = topic_model.visualize_hierarchy()\n",
    "    fig3.write_html(f\"plots/{movie_title}_dendrogram.html\")  # Save as PNG\n",
    "\n",
    "    print(\"Plots saved.\")\n",
    "\n",
    "\n",
    "def create_model_and_plots(chunks):\n",
    "    \n",
    "    hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=3,\n",
    "                                   min_samples=1,\n",
    "                                   cluster_selection_epsilon=0.1)\n",
    "    \n",
    "    umap_model = UMAP(n_components=10, n_neighbors=15, min_dist=0.05, metric='cosine')\n",
    "    \n",
    "    topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model)\n",
    "    topics, probs = topic_model.fit_transform(chunks)\n",
    "    \n",
    "    # View the most common topics\n",
    "    #topic_model.get_topic_info()\n",
    "    \n",
    "    # save plots\n",
    "    create_plots(topic_model, movie_title, top_n_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b345cf00-ff24-4bea-972b-2a3a29887b37",
   "metadata": {},
   "source": [
    "### RUN THE JEWELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe65ba0-751a-49bb-8812-a70fc49ac7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time as time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "movie_title = \"High Noon\"\n",
    "screenplay_text = get_screenplay(movie_title)\n",
    "if screenplay_text:\n",
    "    chunks = clean_and_chunk_text(screenplay_text, top_n_common=200, verbose=True, chunk_size=35)\n",
    "    create_model_and_plots(chunks)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time: {round(end_time - start_time, 2)} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e4b35-66e2-4d27-a1bf-82f145e2e9fe",
   "metadata": {},
   "source": [
    "### RUN THE JEWELS 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703de21b-1f36-463b-98e9-cf6ecdbb1409",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/movie_data/Ground_Hog_Day.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     movie_title \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m screenplay_text:\n\u001b[1;32m---> 15\u001b[0m         chunks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m clean_and_chunk_text(screenplay_text, movie_title, top_n_common\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#create_model_and_plots(chunks)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedder\u001b[38;5;241m.\u001b[39mencode(chunks, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m, in \u001b[0;36mclean_and_chunk_text\u001b[1;34m(screenplay_text, movie_title, top_n_common, verbose, chunk_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Filter out stop words, character names, and common words\u001b[39;00m\n\u001b[0;32m      7\u001b[0m words_to_remove \u001b[38;5;241m=\u001b[39m load_words(top_n_common\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m characters \u001b[38;5;241m=\u001b[39m load_character_names(movie_title\u001b[38;5;241m=\u001b[39mmovie_title)\n\u001b[0;32m      9\u001b[0m filtered_words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m cleaned_words \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (words_to_remove \u001b[38;5;129;01mor\u001b[39;00m characters)]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# filter out short words\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m, in \u001b[0;36mload_character_names\u001b[1;34m(movie_title)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_character_names\u001b[39m(movie_title):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/movie_data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmovie_title\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file2:\n\u001b[0;32m      9\u001b[0m         character_names \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file2)\n\u001b[0;32m     11\u001b[0m     characters \u001b[38;5;241m=\u001b[39m [dicty[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m dicty \u001b[38;5;129;01min\u001b[39;00m character_names[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactors_characters\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/movie_data/Ground_Hog_Day.json'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import time as time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# CREATE EMBEDDINGS\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "chunks = []\n",
    "\n",
    "for filename in train_screenplays:\n",
    "    screenplay_text = get_screenplay(filename)\n",
    "    movie_title = filename.replace(\".txt\", \"\")\n",
    "    \n",
    "    if screenplay_text:\n",
    "        chunks += clean_and_chunk_text(screenplay_text, movie_title, top_n_common=200, verbose=False, chunk_size=150)\n",
    "\n",
    "#create_model_and_plots(chunks)\n",
    "\n",
    "embeddings = embedder.encode(chunks, show_progress_bar=True)\n",
    "end_time = time.time()\n",
    "    \n",
    "print(f\"Time: {round(end_time - start_time, 2)} seconds\\nEmbeddings created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124651c7-aff2-4eee-94c1-245251055e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=10,\n",
    "                                   min_samples=2,\n",
    "                                   cluster_selection_epsilon=0.2)\n",
    "    \n",
    "umap_model = UMAP(n_components=5, n_neighbors=25, min_dist=0.1, metric='cosine')\n",
    "\n",
    "topic_model = BERTopic(umap_model=umap_model, hdbscan_model=hdbscan_model)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ceaf20-c55e-4ea0-a5ef-08dc28393ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fd1d8-e52f-4d89-bd2e-629dbf0fadba",
   "metadata": {},
   "source": [
    "### ZERO-SHOT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11ffa6-f7af-4a8e-8913-325a372a3b32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from collections import Counter\n",
    "\n",
    "movie_title = \"Transformers 2007\"\n",
    "print(\"Screenplay:\", movie_title, \"\\n\")\n",
    "\n",
    "# genres\n",
    "zeroshot_topic_list = genres_descriptions_list\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    min_topic_size=15,\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.8,\n",
    "    representation_model=KeyBERTInspired()\n",
    ")\n",
    "\n",
    "screenplay_text = get_screenplay(movie_title)\n",
    "chunks = clean_and_chunk_text(screenplay_text, top_n_common=200, verbose=True, chunk_size=30)\n",
    "topics, _ = topic_model.fit_transform(chunks)\n",
    "predicted_genres = []\n",
    "\n",
    "verbose = False\n",
    "for i, topic_id in enumerate(topics[:50]):  # Check first 10 documents\n",
    "    topic =genres_list[topic_id]\n",
    "    predicted_genres.append(topic)\n",
    "    if verbose:\n",
    "        print(f\"Document {i}: Predicted Genre - {topic}\")\n",
    "        print(f\"Text Snippet: {chunks[i][:200]}\")  # Show first 200 characters\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Count occurrences of each unique predicted subgenre\n",
    "genre_counts = Counter(predicted_genres)\n",
    "\n",
    "# Total number of documents\n",
    "total_docs = sum(genre_counts.values())\n",
    "\n",
    "# Sort subgenres by count in descending order\n",
    "sorted_counts = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPredicted Genres:\")\n",
    "for genre, count in sorted_counts:\n",
    "    percent = (count / total_docs) * 100  # Calculate percentage\n",
    "    print(f\"{percent:.0f}% | {genre}\")\n",
    "\n",
    "# subgenres\n",
    "zeroshot_topic_list = subgenres_descriptions_list\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=\"thenlper/gte-small\", \n",
    "    min_topic_size=15,\n",
    "    zeroshot_topic_list=zeroshot_topic_list,\n",
    "    zeroshot_min_similarity=.8,\n",
    "    representation_model=KeyBERTInspired()\n",
    ")\n",
    "\n",
    "topics, _ = topic_model.fit_transform(chunks)\n",
    "predicted_subgenres = []\n",
    "\n",
    "verbose = False\n",
    "for i, topic_id in enumerate(topics[:50]):  # Check first 10 documents\n",
    "    topic =subgenres_list[topic_id]\n",
    "    predicted_subgenres.append(topic)\n",
    "    if verbose:\n",
    "        print(f\"Document {i}: Predicted Subgenre - {topic}\")\n",
    "        print(f\"Text Snippet: {chunks[i][:200]}\")  # Show first 200 characters\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# Count occurrences of each unique predicted subgenre\n",
    "subgenre_counts = Counter(predicted_subgenres)\n",
    "\n",
    "# Total number of documents\n",
    "total_docs = sum(subgenre_counts.values())\n",
    "\n",
    "# Sort subgenres by count in descending order\n",
    "sorted_counts = sorted(subgenre_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPredicted Subgenres:\")\n",
    "for subgenre, count in sorted_counts:\n",
    "    percent = (count / total_docs) * 100  # Calculate percentage\n",
    "    print(f\"{percent:.0f}% | {subgenre}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c47bd-6b89-463a-a604-0a7f534d82ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd473af-efe8-49e3-bcc3-d83daa505fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# other plots\n",
    "\n",
    "#topic_model.visualize_term_rank()\n",
    "#topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a04a07-4cc7-41d0-9786-545c441e3c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
